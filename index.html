<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="3D Photorealistic dataset curation with 2D natural imagess">
  <meta name="keywords" content="3D photorealistic dataset, 3D dataset curation, Point cloud">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Beyond Synthetic 3D Benchmark: Constructing Photorealistic 3D Datasets from Large-scale 2D Benchmarks</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({            
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}            
    });
  </script>
  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Beyond Synthetic 3D Benchmark:<br>Constructing Photorealistic 3D Datasets from Large-scale 2D Benchmarks</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">CVPR submission (Paper ID:17805)</span>
          </div>
          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/gyeongman-kim-592257225/">Gyeongman Kim</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/hajin-shim-762b8a126/">Hajin Shim</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://blandocs.github.io/">Hyunsu Kim</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://yunjey.github.io/">Yunjey Choi</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/taki0112/">Junho Kim</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/site/yangeh/">Eunho Yang</a><sup>1,3</sup>
            </span>
          </div> -->

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Korea Advanced Institute of Science and Technology (KAIST), South Korea</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>2</sup>NAVER AI Lab &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block"><sup>3</sup>AITRICS, South Korea</span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
             <span class="link-block">
               <a href=""
                  class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                     <i class="fas fa-file-pdf"></i>
                 </span>
                 <span>Paper</span>
               </a>
             </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                  class="external-link button is-normal is-rounded is-dark">
                 <span class="icon">
                     <i class="fab fa-youtube"></i>
                 </span>
                 <span>Video</span>
               </a>
             </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Slides Link. -->
              <span class="link-block">
                <a href=""
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Slides</span>
                  </a>
              </span>
              <!-- <p>
              This page contains many wide videos which may not display well on a cellphone. Viewing on browser is recommended
              </p> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<section class="hero">
  <div class="container">
    <div class="hero-body">
      <img src="static/images/lift3d_main_figure_v2.png"/>
      <p>Figure.<b>Photorealistc 3D dataset</b>. Our data curation pipeline generates the photorealistc 3D dataset, Lift3D, from single-view 2D image sets, capturing rich real-world information including RGB, structure, and environment. Models trained with Lift3D demonstrate transferability to various downstream vision tasks.</p>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <br>
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          Recent advancements in pretraining methods for 3D data have demonstrated remarkable effectiveness, sparking a surge of interest in the development of foundational 3D models. However, 3D datasets used for pretraining still heavily rely on synthetic data and face limitations in terms of scale and category diversity. These constraints hinder the complete realization of the generalization capabilities of 3D pretrained models, which are vital for various downstream tasks. To address both the sim-to-real gap and dataset scale issues, We introduce a 3D photorealistic dataset curation framework that generates annotated 3D scene and object data from single-view 2D image datasets, fully harnessing real-world objects and the label information present in the natural images. We devise data reconstruction and filtering strategies to preserve the photorealistic qualities in the reconstructed 3D data. Extensive experimental results demonstrate that datasets curated using our framework exhibit superior generalizability across a diverse range of downstream tasks when compared to existing benchmark datasets.
        </div>
        <br>
      </div>
    </div>
  </div>
</section>

<!-- Method overview -->
<section class="hero">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <br>
        <h2 class="title is-3">Method Overview</h2>
        <!-- <div class="column">
          <img src="static/images/overview.png"/>
          <br>
          <h2 class="subtitle has-text-centered">Overview of our Diffusion Video Autoencoder</h2>
        </div> -->
        <br>
        <div class="content has-text-justified">
          We describe our simple yet effective procedure for constructing photorealistic point clouds from sets of natural images, aiming to enhance the versatility of 3D pretrained models in downstream real-world 3D vision tasks. The process begins with lifting images into point clouds, guided by the estimated depth map. Here, we observe a substantial variability in the fidelity of reconstructed 3D data, ranging from realistic point clouds to instances having noisy points or infeasible structures. Given that imprecise data may convey misleading signals to the model, hindering the model from learning a versatile structural prior, we devise data refinement strategies at both point and instance levels. Armed with this refinement process, photorealistic point clouds are selectively curated by filtering out erroneous points — byproducts of the reconstruction process — and excluding geometrically unnatural instances, achieved without any human supervision.
        </div>
        <br>
      </div>
    </div>
  </div>
</section>

<!-- Comparisons -->
<!-- <section class="hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <br>
        <div class="section-title">
          <h2 class="title is-3 is-centered">Comparison of Temporal Consistency for "beard"</h2>
        </div>
        <br>
        <video id="compare_beard" autoplay controls loop muted width="100%">
          <source src="static/videos/Comparison_video.mp4"
                  type="video/mp4">
        </video>
        <div class="columns vertical_center">
          <div class="column is-one-fifths"><div class="columns"><div class="column">
            <p>Original</p>
          </div></div></div>
          <div class="column is-one-fifths"><div class="columns"><div class="column">
            <p>Latent Transformer</p>
          </div></div></div>
          <div class="column is-one-fifths"><div class="columns"><div class="column">
            <p>STIT</p>
          </div></div></div>
          <div class="column is-one-fifths"><div class="columns"><div class="column">
            <p>VideoEditGAN</p>
          </div></div></div>
          <div class="column is-one-fifths"><div class="columns"><div class="column">
            <p>Ours</p>
          </div></div></div>
        </div>
        <h2 class="subtitle has-text-centered"><b>We demonstrate that only our diffusion video autoencoder successfully produces the consistent result.</b></h2>
        <br>
      </div>  
    </div>
  </div>
</section> -->



<section class="hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <br>
        <div class="section-title">
          <h2 class="title is-3 is-centered">Real examples of 3D scene pointcloud in Lift3D-S dataset</h2>
        </div>
        <br>
        <div style="width: 50%; height: 200px; float: left;">
          <img src="static/images/ADE_val_00000040.jpg" />
        </div>
        <div style="width: 50%; height: 200px; float: right;">
        <img src="static/gifs/ADE_val_00000040.gif" loop=infinite />
        </div>
        <br>

        <div style="width: 49%; height: 200px; float: left;">
          <img src="static/images/ADE_val_00000077.jpg" />
        </div>
        <div style="width: 49%; height: 200px; float: right;">
        <img src="static/gifs/ADE_val_00000077.gif" loop=infinite />
        </div>
      </div>  
    </div>
  </div>
</section>


<!-- Additional Examples -->
<!-- <section class="hero">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <br>
        <div class="section-title">
          <h2 class="title is-3 is-centered" id="additional">Additional Examples</h2>
        </div>
        <div class="publication-video-small">
          <h2 class="subtitle has-text-centered">+Beard</h2>
          <video id="beard" autoplay controls loop muted width="60%">
            <source src="static/videos/+Beard_CLIP.mp4"
                    type="video/mp4">
          </video>
          <div class="columns vertical_center">
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Original</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>STIT</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
          </div>
          <br>
          <h2 class="subtitle has-text-centered">+Eyeglasses</h2>
          <video id="eyeglasses" autoplay controls loop muted width="60%">
          <source src="static/videos/+Eyeglasses_CLIP.mp4"
                  type="video/mp4">
          </video>
          <div class="columns vertical_center">
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Original</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>STIT</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
          </div>
          <br>
          <h2 class="subtitle has-text-centered">+Mustache</h2>
          <video id="mustache" autoplay controls loop muted width="60%">
            <source src="static/videos/+Mustache_CLIP.mp4"
                    type="video/mp4">
          </video>
          <div class="columns vertical_center">
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Original</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>STIT</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
          </div>
          <h2 class="subtitle has-text-centered"><b>Our method shows temporally consistent results.</b></h2>
        </div>
        <br>
        <div class="publication-video-small">
          <h2 class="subtitle has-text-centered">+Beard</h2>
          <video id="occluded" autoplay controls loop muted width="60%">
            <source src="static/videos/+Beard_occluded.mp4"
                    type="video/mp4">
          </video>
          <div class="columns vertical_center">
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Original</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>STIT</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
          </div>
          <h2 class="subtitle has-text-centered"><b>Our method also robustly reconstructs and edits the unusual case such as the hand-occluded face effectively.</b></h2>
        </div>
        <br>
        <div class="publication-video-small">
          <h2 class="subtitle has-text-centered">-Sideburns</h2>
          <video id="sideburns" autoplay controls loop muted width="60%">
            <source src="static/videos/-Sideburns_Classifier_long.mp4"
                    type="video/mp4">
          </video>
          <div class="columns vertical_center">
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Original</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>STIT</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p></p>
            </div></div></div>
          </div>
          <h2 class="subtitle has-text-centered"><b>Moreover, entire frames of long video can be edited at once by modifying the single identity feature.</b></h2>
        </div>
        <br>
      </div>
    </div>
  </div>
</section> -->

<!-- Inference Time -->
<!-- <section class="hero is-light">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <br>
        <div class="section-title">
          <h2 class="title is-3 is-centered" id="additional">Inference Time Comparison</h2>
        </div>
        <div class="publication-video-small">
          <video id="sampler" autoplay controls loop muted width="100%">
            <source src="static/videos/Comparison_time.mp4"
                    type="video/mp4">
          </video>
          <div class="columns vertical_center">
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Original</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>STIT<br>12.0 sec/frame</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours (T=1000)<br>62.4 sec/frame</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours (T=100)<br>7.3 sec/frame</p>
            </div></div></div>
            <div class="column is-one-fifths"><div class="columns"><div class="column">
              <p>Ours (+Sampler)<br>2.9 sec/frame</p>
            </div></div></div>
          </div>
          <h2 class="subtitle has-text-centered"><b>Furthermore, our method can utilize ODE samplers to reduce time with comparable quality.</b></h2>
        </div>
        <br>
      </div>
    </div>
  </div>
</section> -->


<!-- <section class="hero" id="BibTeX">
  <br>
  <div class="container content">
    <h2 class="title">BibTeX</h2>
    <p>If you find our work useful, please cite our paper:</p>
    <pre><code>@InProceedings{Kim_2023_CVPR,
      author={Kim, Gyeongman and Shim, Hajin and Kim, Hyunsu and Choi, Yunjey and Kim, Junho and Yang, Eunho},
      title={Diffusion Video Autoencoders: Toward Temporally Consistent Face Video Editing via Disentangled Video Encoding},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      month={June},
      year={2023},
      pages={6091-6100}
}
    </code></pre>
</div>
</section> -->

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
